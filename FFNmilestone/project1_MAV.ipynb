{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculadora -10 a 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rich import print, console\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m,\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear un dataset de 1000 filas por 2 columnas. Cada columna contiene enteros aleatorios entre -10 y 10\n",
    "data = np.random.randint(-10, 10, (100, 2))\n",
    "\n",
    "# Crear un dataset de 1000 filas por 1 columna. Cada columna contiene la suma de los valores de las columnas de X\n",
    "labels = np.sum(data, axis=1)\n",
    "\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train_data: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>, train_labels: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "train_data: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m90\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, train_labels: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test_data: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>, test_labels: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test_data: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, test_labels: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-10</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>.,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>.,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m-5\u001b[0m., \u001b[1;36m-10\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m5\u001b[0m.,   \u001b[1;36m8\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m0\u001b[0m.,   \u001b[1;36m3\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m-1\u001b[0m.,   \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m3\u001b[0m.,  \u001b[1;36m-8\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-15</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-15\u001b[0m,  \u001b[1;36m13\u001b[0m,   \u001b[1;36m3\u001b[0m,  \u001b[1;36m-1\u001b[0m,  \u001b[1;36m-5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( data ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "print(f\"train_data: {train_data.shape}, train_labels: {train_labels.shape}\")\n",
    "print(f\"test_data: {test_data.shape}, test_labels: {test_labels.shape}\")\n",
    "\n",
    "# show the first rows of the data and the labels\n",
    "print(test_data[:5])\n",
    "print(test_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m90\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.50165451</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.30663455</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2</span>.        <span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.78008032</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.30663455</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.        <span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.97510034</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25352609</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5</span>.        <span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.97510034</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.78008032</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2</span>.        <span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.78008032</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.09751004</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>.        <span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.50165451\u001b[0m  \u001b[1;36m1.30663455\u001b[0m \u001b[1;36m-2\u001b[0m.        \u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m \u001b[1;36m0.78008032\u001b[0m  \u001b[1;36m1.30663455\u001b[0m \u001b[1;36m11\u001b[0m.        \u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m\u001b[1;36m-0.97510034\u001b[0m  \u001b[1;36m0.25352609\u001b[0m \u001b[1;36m-5\u001b[0m.        \u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m\u001b[1;36m-0.97510034\u001b[0m  \u001b[1;36m0.78008032\u001b[0m \u001b[1;36m-2\u001b[0m.        \u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m \u001b[1;36m0.78008032\u001b[0m \u001b[1;36m-0.09751004\u001b[0m  \u001b[1;36m3\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Normalize the data\n",
    "train_dataN = (train_data - train_data.mean()) / train_data.std()\n",
    "test_dataN  = (test_data - test_data.mean()) / test_data.std()\n",
    "\n",
    "# train_dataN = train_data\n",
    "# test_dataN  = test_data\n",
    "\n",
    "print(train_dataN.shape, train_labels.shape)\n",
    "\n",
    "# show the first rows of train_dataN and train_labels\n",
    "print(np.hstack((train_dataN[:5], train_labels[:5].reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test loader batch size:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test loader batch size:  \u001b[1;36m90\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">There are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches, each with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> samples.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "There are \u001b[1;36m2\u001b[0m batches, each with \u001b[1;36m32\u001b[0m samples.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: convert into PyTorch Datasets\n",
    "train_dataTds = TensorDataset(train_dataN, train_labels)\n",
    "test_dataTds  = TensorDataset(test_dataN, test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_dataTds, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_dataTds, batch_size=test_dataTds.tensors[0].shape[0])\n",
    "\n",
    "# show the dataloader object and the shape of the data (must be the same as the original data)\n",
    "print(\"test loader batch size: \", train_loader.dataset.tensors[0].shape[0])\n",
    "print(f'There are {len(train_loader)} batches, each with {batchsize} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the DL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pérdida en PyTorch\n",
    "![Funciones de pérdida en PyTorch](../_USEFUL_TABLES/loss_functions_pytorch_nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizadores en PyTorch\n",
    "![optimizadores en PyTorch](../_USEFUL_TABLES/optimizers_pytorch_optim.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheModel():\n",
    "\n",
    "  class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(2,4)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(4,4)\n",
    "      self.fc2 = nn.Linear(4,4)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(4,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = Net()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(net.parameters(), lr=.01)  # Simple and efficient, especially for large-scale learning and convex problems. General problems (typically for large datasets)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Net</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>input<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "----\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossEntropyLoss</span><span style=\"font-weight: bold\">()</span>\n",
       "----\n",
       "SGD <span style=\"font-weight: bold\">(</span>\n",
       "Parameter Group <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    dampening: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    differentiable: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "    foreach: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    fused: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    lr: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>\n",
       "    maximize: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "    momentum: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    nesterov: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "    weight_decay: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mNet\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0minput\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0moutput\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n",
       "----\n",
       "\u001b[1;35mCrossEntropyLoss\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "----\n",
       "SGD \u001b[1m(\u001b[0m\n",
       "Parameter Group \u001b[1;36m0\u001b[0m\n",
       "    dampening: \u001b[1;36m0\u001b[0m\n",
       "    differentiable: \u001b[3;91mFalse\u001b[0m\n",
       "    foreach: \u001b[3;35mNone\u001b[0m\n",
       "    fused: \u001b[3;35mNone\u001b[0m\n",
       "    lr: \u001b[1;36m0.01\u001b[0m\n",
       "    maximize: \u001b[3;91mFalse\u001b[0m\n",
       "    momentum: \u001b[1;36m0\u001b[0m\n",
       "    nesterov: \u001b[3;91mFalse\u001b[0m\n",
       "    weight_decay: \u001b[1;36m0\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net,lossfun,optimizer = createTheModel()\n",
    "print(net, lossfun, optimizer, sep=\"\\n----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6853</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2838</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1738</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2247</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0234</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0386</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3537</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1087</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2523</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0114</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.7318</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2493</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1864</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2723</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0346</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0117</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3610</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1074</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1200</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0367</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8264</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2690</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2021</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2677</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0403</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0174</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3479</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0656</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0313</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1345</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9211</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2887</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2178</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2631</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0460</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0466</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3347</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0239</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0574</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2323</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0158</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3084</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2336</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2585</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0517</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0758</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3216</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0178</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1461</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3302</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.6853\u001b[0m, \u001b[1;36m-0.2838\u001b[0m, \u001b[1;36m-0.1738\u001b[0m,  \u001b[1;36m0.2247\u001b[0m, \u001b[1;36m-0.0234\u001b[0m, \u001b[1;36m-0.0386\u001b[0m, \u001b[1;36m-0.3537\u001b[0m,  \u001b[1;36m0.1087\u001b[0m,\n",
       "          \u001b[1;36m0.2523\u001b[0m, \u001b[1;36m-0.0114\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.7318\u001b[0m, \u001b[1;36m-0.2493\u001b[0m, \u001b[1;36m-0.1864\u001b[0m,  \u001b[1;36m0.2723\u001b[0m,  \u001b[1;36m0.0346\u001b[0m, \u001b[1;36m-0.0117\u001b[0m, \u001b[1;36m-0.3610\u001b[0m,  \u001b[1;36m0.1074\u001b[0m,\n",
       "          \u001b[1;36m0.1200\u001b[0m, \u001b[1;36m-0.0367\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.8264\u001b[0m, \u001b[1;36m-0.2690\u001b[0m, \u001b[1;36m-0.2021\u001b[0m,  \u001b[1;36m0.2677\u001b[0m,  \u001b[1;36m0.0403\u001b[0m,  \u001b[1;36m0.0174\u001b[0m, \u001b[1;36m-0.3479\u001b[0m,  \u001b[1;36m0.0656\u001b[0m,\n",
       "          \u001b[1;36m0.0313\u001b[0m, \u001b[1;36m-0.1345\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.9211\u001b[0m, \u001b[1;36m-0.2887\u001b[0m, \u001b[1;36m-0.2178\u001b[0m,  \u001b[1;36m0.2631\u001b[0m,  \u001b[1;36m0.0460\u001b[0m,  \u001b[1;36m0.0466\u001b[0m, \u001b[1;36m-0.3347\u001b[0m,  \u001b[1;36m0.0239\u001b[0m,\n",
       "         \u001b[1;36m-0.0574\u001b[0m, \u001b[1;36m-0.2323\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-1.0158\u001b[0m, \u001b[1;36m-0.3084\u001b[0m, \u001b[1;36m-0.2336\u001b[0m,  \u001b[1;36m0.2585\u001b[0m,  \u001b[1;36m0.0517\u001b[0m,  \u001b[1;36m0.0758\u001b[0m, \u001b[1;36m-0.3216\u001b[0m, \u001b[1;36m-0.0178\u001b[0m,\n",
       "         \u001b[1;36m-0.1461\u001b[0m, \u001b[1;36m-0.3302\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Verify the model with a sample (the shape of the output must be 1 column)\n",
    "X = torch.tensor([[1.,2.],[3.,4.],[5.,6.],[7.,8.],[9.,10.]]).float()\n",
    "yHat = net(X)\n",
    "print(yHat)\n",
    "print(X.shape, yHat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function that trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 50\n",
    "  \n",
    "  # create a new model\n",
    "  net, lossfun, optimizer = createTheModel()\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros((numepochs, 2))\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "  \n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    \n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "    #   print(f'X: {X}')\n",
    "    #   print(f'yHat: {yHat}')\n",
    "    #   print(f'y: {y}')\n",
    "      loss = lossfun(yHat, y)  # lossfun returns a Tensor with the loss\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())  # .item() returns the scalar value held in the loss tensor\n",
    "\n",
    "      # compute accuracy\n",
    "    #   print(f'y: {y}')\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi, 0] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "    loss = lossfun(yHat,y)\n",
    "    losses[epochi, 1] = loss.item()\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model and show the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 10 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainAcc,testAcc,losses,net \u001b[38;5;241m=\u001b[39m \u001b[43mtrainTheModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainAcc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainAcc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtestAcc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtestAcc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m yHat \u001b[38;5;241m=\u001b[39m net(X)\n",
      "Cell \u001b[1;32mIn[126], line 31\u001b[0m, in \u001b[0;36mtrainTheModel\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m   yHat \u001b[38;5;241m=\u001b[39m net(X)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#   print(f'X: {X}')\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#   print(f'yHat: {yHat}')\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#   print(f'y: {y}')\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[43mlossfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43myHat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# lossfun returns a Tensor with the loss\u001b[39;00m\n\u001b[0;32m     33\u001b[0m   \u001b[38;5;66;03m# backprop\u001b[39;00m\n\u001b[0;32m     34\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Python\\UDEMY - DeepUnderstandingOfDeepLearning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\UDEMY - DeepUnderstandingOfDeepLearning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python\\UDEMY - DeepUnderstandingOfDeepLearning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python\\UDEMY - DeepUnderstandingOfDeepLearning\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 10 is out of bounds."
     ]
    }
   ],
   "source": [
    "trainAcc,testAcc,losses,net = trainTheModel()\n",
    "\n",
    "print(f\"trainAcc: {trainAcc}\", f\"testAcc: {testAcc}\", f\"losses: {losses}\", sep=\"\\n----\\n\")\n",
    "\n",
    "yHat = net(X)\n",
    "print(yHat)\n",
    "print(X[:5], yHat[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training data range <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-10</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training data range \u001b[1;36m-10\u001b[0m to \u001b[1;36m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Test data range <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-10</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Test data range \u001b[1;36m-10\u001b[0m to \u001b[1;36m8\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirm ranges of train and test data\n",
    "\n",
    "print('Training data range %g to %g' \n",
    "      %(torch.min(train_loader.dataset.tensors[0]),torch.max(train_loader.dataset.tensors[0])) )\n",
    "\n",
    "print('Test data range %g to %g' \n",
    "      %(torch.min(test_loader.dataset.tensors[0]),torch.max(test_loader.dataset.tensors[0])) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
